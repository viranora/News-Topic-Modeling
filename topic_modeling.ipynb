{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "237bc550-2732-416e-96e3-d8f2d7929b35",
   "metadata": {},
   "source": [
    "# Unsupervised Topic Modeling with NMF\n",
    "\n",
    "Goal: To discover 20 hidden topics from the \"20 Newsgroups\" dataset using TF-IDF and NMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f018e68-8632-46b1-a90b-b3721d11ad90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import Libraries & Load Data\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aa05b67-d74a-4f4d-9873-28e15d887b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 11314 documents.\n",
      "\n",
      "--- Example Document ---\n",
      "I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n"
     ]
    }
   ],
   "source": [
    "# We set 'remove' to ('headers', 'footers', 'quotes') to get just the text body.\n",
    "# We will only use the 'train' set for our unsupervised learning.\n",
    "data = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), shuffle=True, random_state=42)\n",
    "\n",
    "# The data's text is in data.data\n",
    "# The \"true\" labels (which we will ignore for training) are in data.target\n",
    "documents = data.data\n",
    "\n",
    "# Let's see how many documents we have and an example\n",
    "print(f\"Loaded {len(documents)} documents.\")\n",
    "print(\"\\n--- Example Document ---\")\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ea1c601-e3f1-4103-8c39-065cd71feda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (11314, 39115)\n",
      "Vocabulary size: 39115\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Vectorization (TF-IDF)\n",
    "\n",
    "# We need to filter our words carefully.\n",
    "# max_df=0.95: Ignore words that appear in > 95% of documents (too common, e.g., \"the\")\n",
    "# min_df=2: Ignore words that appear in < 2 documents (too rare / typos)\n",
    "# stop_words='english': Remove common English stop words\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "\n",
    "# Fit the vectorizer to our documents and transform them into a matrix\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Get the feature names (the words in our vocabulary)\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")\n",
    "print(f\"Vocabulary size: {len(feature_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "280d092c-a980-42b2-b3b9-ffcbe3fe1e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting NMF model... (This may take a moment)\n",
      "NMF model fitted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Train the NMF Model\n",
    "# ---\n",
    "# We will ask NMF to find 20 topics (n_components=20).\n",
    "\n",
    "# %%\n",
    "# Define the number of topics\n",
    "num_topics = 20\n",
    "\n",
    "# Initialize NMF\n",
    "# n_init='auto' helps find a stable solution\n",
    "# random_state=42 ensures our results are reproducible\n",
    "nmf_model = NMF(n_components=num_topics, random_state=42, max_iter=500)\n",
    "\n",
    "# Fit the NMF model to our TF-IDF matrix\n",
    "# This step can take a minute or two\n",
    "print(\"Fitting NMF model... (This may take a moment)\")\n",
    "nmf_model.fit(tfidf_matrix)\n",
    "\n",
    "print(\"NMF model fitted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d903f374-9184-4bf3-831f-d19dcf23e4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying top 10 words for each of the 20 topics:\n",
      "\n",
      "Topic #1:\n",
      "people | government | gun | right | law | guns | state | rights | think | make\n",
      "--------------------------------------------------------------------------------\n",
      "Topic #2:\n",
      "file | files | program | ftp | directory | image | format | zip | gif | bmp\n",
      "--------------------------------------------------------------------------------\n",
      "Topic #3:\n",
      "god | jesus | bible | believe | faith | christ | christian | christians | church | life\n",
      "--------------------------------------------------------------------------------\n",
      "Topic #4:\n",
      "geb | dsl | n3jxp | chastity | cadre | pitt | shameful | intellect | skepticism | surrender\n",
      "--------------------------------------------------------------------------------\n",
      "Topic #5:\n",
      "key | chip | encryption | clipper | keys | escrow | algorithm | government | use | secure\n",
      "--------------------------------------------------------------------------------\n",
      "Topic #6:\n",
      "drive | disk | hard | drives | floppy | boot | cd | ide | power | internal\n",
      "--------------------------------------------------------------------------------\n",
      "Topic #7:\n",
      "armenian | armenians | turkish | genocide | armenia | turkey | turks | said | soviet | greek\n",
      "--------------------------------------------------------------------------------\n",
      "Topic #8:\n",
      "thanks | advance | mail | hi | looking | info | help | appreciated | information | address\n",
      "--------------------------------------------------------------------------------\n",
      "Topic #9:\n",
      "space | nasa | shuttle | launch | orbit | data | earth | moon | station | lunar\n",
      "--------------------------------------------------------------------------------\n",
      "Topic #10:\n",
      "card | video | monitor | vga | cards | color | drivers | bus | driver | ram\n",
      "--------------------------------------------------------------------------------\n",
      "Topic #11:\n",
      "game | team | games | year | players | season | hockey | play | win | league\n",
      "--------------------------------------------------------------------------------\n",
      "Topic #12:\n",
      "windows | dos | ms | version | running | os | microsoft | nt | drivers | driver\n",
      "--------------------------------------------------------------------------------\n",
      "Topic #13:\n",
      "window | motif | server | application | problem | manager | display | use | using | screen\n",
      "--------------------------------------------------------------------------------\n",
      "Topic #14:\n",
      "does | know | anybody | mean | doesn | program | let | appreciated | exist | help\n",
      "--------------------------------------------------------------------------------\n",
      "Topic #15:\n",
      "00 | sale | shipping | 10 | 50 | new | offer | price | 20 | 15\n",
      "--------------------------------------------------------------------------------\n",
      "Topic #16:\n",
      "car | bike | cars | engine | miles | dealer | new | good | speed | insurance\n",
      "--------------------------------------------------------------------------------\n",
      "Topic #17:\n",
      "just | don | like | think | ve | good | really | time | ll | say\n",
      "--------------------------------------------------------------------------------\n",
      "Topic #18:\n",
      "edu | com | mail | list | email | send | cs | address | article | university\n",
      "--------------------------------------------------------------------------------\n",
      "Topic #19:\n",
      "scsi | ide | controller | bus | isa | pc | bit | mac | devices | dma\n",
      "--------------------------------------------------------------------------------\n",
      "Topic #20:\n",
      "israel | israeli | jews | arab | arabs | jewish | lebanese | lebanon | peace | israelis\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Interpret the Topics\n",
    "\n",
    "def display_topics(model, feature_names, num_top_words):\n",
    "    \"\"\"\n",
    "    Prints the top words for each topic in an NMF model.\n",
    "    \"\"\"\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        # model.components_ is shape [num_topics, num_features]\n",
    "        # We sort the weights in descending order and get the indices\n",
    "        top_word_indices = topic.argsort()[::-1]\n",
    "        \n",
    "        # Get the top N words\n",
    "        top_words = [feature_names[i] for i in top_word_indices[:num_top_words]]\n",
    "        \n",
    "        print(f\"Topic #{topic_idx + 1}:\")\n",
    "        print(\" | \".join(top_words))\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "# Let's see the top 10 words for each of our 20 topics\n",
    "num_top_words = 10\n",
    "print(f\"Displaying top {num_top_words} words for each of the {num_topics} topics:\\n\")\n",
    "display_topics(nmf_model, feature_names, num_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eccbcf65-a959-4719-93ce-53279dff0357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test Document --- \n",
      "I have uploaded the Windows On-Line Review shareware edition to\n",
      "ftp.cica.indiana.edu as /pub/pc/win3/uploads/wolrs7.zip.\n",
      "\n",
      "It is an on-line magazine which contains reviews of some shareware\n",
      "products...I grabbed it from the Windows On-Line BBS.\n",
      "\n",
      "--\n",
      "--------------------------------------------------------------------------------\n",
      "Predicted dominant topic index: 12\n",
      "\n",
      "--- Top Words for Predicted Topic ---\n",
      "windows | dos | ms | version | running | os | microsoft | nt | drivers | driver\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Test the Model on New Documents\n",
    "\n",
    "# We can get the test data from the same dataset\n",
    "test_data = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), shuffle=True, random_state=42)\n",
    "test_documents = test_data.data\n",
    "\n",
    "# Let's pick a random document\n",
    "test_doc_text = test_documents[10]\n",
    "print(f\"--- Test Document --- \\n{test_doc_text}\\n\" + \"-\"*80)\n",
    "\n",
    "# 1. Transform the document using the *same* TF-IDF vectorizer\n",
    "test_doc_tfidf = tfidf_vectorizer.transform([test_doc_text])\n",
    "\n",
    "# 2. Transform the TF-IDF vector using the *fitted* NMF model\n",
    "# This gives us a list of weights for each of the 20 topics.\n",
    "topic_weights = nmf_model.transform(test_doc_tfidf)\n",
    "\n",
    "# 3. Get the most likely topic\n",
    "# We use argmax to find the index of the highest weight\n",
    "dominant_topic_idx = topic_weights.argmax()\n",
    "print(f\"Predicted dominant topic index: {dominant_topic_idx + 1}\")\n",
    "\n",
    "# 4. Display the top words for that topic to confirm\n",
    "print(\"\\n--- Top Words for Predicted Topic ---\")\n",
    "topic_words = [feature_names[i] for i in nmf_model.components_[dominant_topic_idx].argsort()[::-1][:10]]\n",
    "print(\" | \".join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b01eb3a-523a-4b5f-8f08-dd8c0baa99ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
